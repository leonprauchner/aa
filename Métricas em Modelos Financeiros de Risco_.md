

# **Métricas de Erro em Modelagem de Risco de Crédito: Uma Análise Exaustiva para Validação de Modelos de PD, LGD, EAD e Renda**

## **Parte I: A Metrologia do Erro do Modelo: Uma Análise Fundamental**

### **1\. Introdução: O Imperativo da Validação de Modelos em Risco Financeiro**

A validação de modelos de risco de crédito transcende a simples verificação de uma métrica de erro; é um processo de governança contínuo e multifacetado, essencial para a estabilidade e conformidade das instituições financeiras. O objetivo é duplo e serve a múltiplos stakeholders, desde gestores de negócio a auditores e reguladores. Primeiramente, o modelo deve **discriminar** corretamente entre diferentes níveis de risco (rank-ordering), e, em segundo lugar, deve **calibrar** com precisão a magnitude desse risco (point-estimation).1 A falha em qualquer um desses objetivos pode levar a provisionamento inadequado, alocação de capital ineficiente e decisões de negócio equivocadas.  
O ambiente regulatório, moldado por frameworks como IFRS 9 e Basileia III, intensificou o escrutínio sobre a validação de modelos. O IFRS 9, com sua abordagem de Perdas de Crédito Esperadas (ECL \- Expected Credit Losses), revolucionou a prática ao exigir que os modelos sejam *forward-looking*, incorporando previsões macroeconômicas para refletir uma visão *Point-in-Time* (PiT) do risco.4 Esta abordagem contrasta com a visão  
*Through-the-Cycle* (TTC) de Basileia, que prioriza a estabilidade das estimativas ao longo de um ciclo econômico completo.8 Consequentemente, a validação de um modelo IFRS 9 deve demonstrar não apenas sua solidez conceitual e precisão, mas também sua capacidade de responder de forma sensata às mudanças nas condições econômicas futuras.1  
Nesse contexto, o risco do modelo — definido pela orientação supervisória como o "potencial para consequências adversas de decisões baseadas em resultados de modelos incorretos ou mal utilizados" 3 — torna-se uma preocupação central. Uma das fontes mais críticas e, por vezes, subestimadas de risco do modelo é a seleção de métricas de validação inadequadas. Uma métrica mal escolhida pode mascarar deficiências significativas, como a incapacidade de prever perdas extremas ou um viés sistemático nas previsões, levando a uma falsa sensação de segurança.2  
A validação de modelos de crédito, especialmente sob o IFRS 9, enfrenta uma tensão inerente entre a necessidade de *precisão preditiva* e a *estabilidade dos resultados*. A natureza *forward-looking* do IFRS 9 favorece modelos que se adaptam rapidamente às novas informações e às mudanças nas previsões macroeconômicas.6 Tais modelos, quando avaliados em um backtest, podem apresentar métricas de erro de previsão superiores (por exemplo, um RMSE mais baixo). No entanto, essa mesma reatividade pode gerar uma volatilidade significativa nos lucros reportados de um trimestre para o outro, algo que a gestão sênior e os investidores tendem a ver com desconfiança, pois dificulta a distinção entre o desempenho real do negócio e o ruído do modelo.16 Um modelo excessivamente estável, por outro lado, corre o risco de não reconhecer as perdas de forma tempestiva, contrariando o princípio fundamental do IFRS 9 de reconhecimento antecipado de perdas.17 Portanto, a estrutura de validação não pode otimizar apenas para a minimização do erro de previsão. Deve incorporar uma avaliação estratégica que equilibre precisão e estabilidade, reconhecendo que a escolha do modelo "campeão" é uma decisão de negócio que pondera esses dois objetivos, muitas vezes conflitantes.

### **2\. Métricas de Erro Centrais: A Troca entre Magnitude e Robustez**

A avaliação quantitativa de um modelo de regressão ou previsão começa com a medição da distância entre os valores previstos e os valores reais. As métricas mais fundamentais para essa tarefa são o Mean Absolute Error (MAE) e o Root Mean Squared Error (RMSE). A escolha entre elas não é meramente técnica, mas reflete uma suposição fundamental sobre como a instituição pondera erros de diferentes magnitudes.

#### **Mean Absolute Error (MAE)**

O Erro Absoluto Médio é a mais direta e intuitiva das métricas de erro.

* Fórmula e Interpretação: O MAE é calculado como a média dos valores absolutos das diferenças entre os valores previstos (y^​i​) e os valores reais (yi​), conforme a fórmula:  
  MAE=n1​i=1∑n​∣yi​−y^​i​∣

  .18 Sua interpretação é simples: representa o erro médio absoluto e é expresso na mesma unidade da variável-alvo.20 Por exemplo, um MAE de €500 em um modelo de previsão de perda significa que, em média, as previsões estão erradas em €500, para mais ou para menos.  
* **Vantagens:** A principal virtude do MAE é sua robustez a outliers. Como os erros não são elevados ao quadrado, um erro extremo tem um impacto linear, e não quadrático, na métrica geral. Isso o torna particularmente adequado para conjuntos de dados que contêm valores extremos ou quando não se deseja que grandes erros individuais dominem a avaliação do modelo.19 Do ponto de vista estatístico, a minimização do MAE leva a um modelo que prevê a mediana da distribuição da variável-alvo, uma medida de tendência central mais robusta para distribuições assimétricas ou com múltiplas modas.23  
* **Desvantagens:** A robustez do MAE também é sua principal fraqueza em certos contextos. Ao tratar todos os erros de forma linear, ele não penaliza erros grandes de forma mais severa do que erros pequenos, o que pode ser indesejável em aplicações de risco financeiro, onde grandes erros são catastroficamente mais custosos.19 Além disso, a função de valor absoluto não é diferenciável em zero, o que pode apresentar desafios para algoritmos de otimização baseados em gradiente durante o treinamento do modelo.19

#### **Root Mean Squared Error (RMSE)**

O Erro Quadrático Médio da Raiz é uma das métricas mais utilizadas em modelagem estatística, favorecendo modelos que evitam grandes erros.

* Fórmula e Interpretação: O RMSE é a raiz quadrada da média dos erros ao quadrado:  
  RMSE=n1​i=1∑n​(yi​−y^​i​)2​

  .19 Assim como o MAE, é expresso na mesma unidade da variável-alvo, o que o torna mais interpretável que seu precursor, o Erro Quadrático Médio (MSE).20 O RMSE pode ser intuitivamente entendido como o desvio padrão dos resíduos (erros de previsão).27  
* **Vantagens:** A característica definidora do RMSE é a elevação dos erros ao quadrado, o que impõe uma penalidade desproporcionalmente grande a erros maiores.19 Isso está alinhado com a aversão ao risco em muitas aplicações financeiras, onde um único erro de previsão massivo (por exemplo, subestimar uma grande perda de crédito) é muito mais prejudicial do que vários pequenos erros. A função de perda quadrática é diferenciável em todos os pontos, o que a torna matematicamente conveniente para otimização.20 A minimização do RMSE leva a um modelo que prevê a média da distribuição da variável-alvo.23  
* **Desvantagens:** A sensibilidade a outliers é o seu maior ponto fraco. Um único valor atípico com um grande erro de previsão pode inflar drasticamente o RMSE, fornecendo uma visão potencialmente enganosa do desempenho geral do modelo na maioria das observações.19

A decisão entre MAE e RMSE transcende a estatística e reflete uma estratégia de negócio implícita sobre a função de perda da instituição. A escolha pelo RMSE sugere que o custo de um erro aumenta quadraticamente com sua magnitude; por exemplo, um erro de €2 milhões é considerado quatro vezes mais custoso que um erro de €1 milhão. Em contrapartida, a escolha pelo MAE implica que o custo do erro é linear; o erro de €2 milhões é apenas duas vezes mais custoso que o de €1 milhão.23 Ao selecionar a métrica de validação, a equipe de modelagem está, de fato, codificando a aversão ao risco da instituição em relação a erros de previsão de diferentes tamanhos. Essa escolha deve ser explicitamente documentada e justificada não apenas com base em propriedades estatísticas (como robustez a outliers), mas também em termos de seu alinhamento com os objetivos estratégicos de risco do negócio.2

### **3\. Métricas Escaladas e Percentuais: O Desafio da Comparabilidade**

Embora MAE e RMSE sejam excelentes para avaliar um modelo em um único conjunto de dados, eles são dependentes da escala, tornando a comparação de modelos entre portfólios com diferentes magnitudes (por exemplo, um modelo de renda para clientes de varejo versus um modelo de EAD para grandes corporações) impraticável. Métricas percentuais e escaladas resolvem esse problema.

#### **Mean Absolute Percentage Error (MAPE)**

O Erro Percentual Absoluto Médio é popular por sua interpretabilidade e independência de escala.

* Fórmula e Interpretação: O MAPE mede o erro médio como uma porcentagem do valor real:  
  MAPE=n1​i=1∑n​​yi​yi​−y^​i​​​×100%

  .19 Sua principal atração é a comunicação intuitiva. Uma declaração como "nosso modelo de previsão de vendas erra em média 10%" é facilmente compreendida pela gestão e por stakeholders não técnicos.29 Por ser adimensional, permite a comparação direta do desempenho de modelos em diferentes portfólios ou para prever variáveis com unidades distintas.19  
* **Desvantagens Críticas:** O MAPE possui falhas significativas que limitam sua aplicação:  
  1. **Problema do Zero:** Se qualquer valor real (yi​) for zero, a métrica torna-se indefinida devido à divisão por zero. Isso é um problema comum em dados de demanda ou perdas, onde zeros são observações válidas e frequentes.28  
  2. **Assimetria:** O MAPE penaliza erros de forma assimétrica. O intervalo de erro para previsões abaixo do real (under-forecasting) é limitado a 100%, enquanto para previsões acima do real (over-forecasting) é ilimitado. Isso pode criar um viés, incentivando modelos que minimizam o MAPE a produzir previsões sistematicamente mais baixas.29  
  3. **Inflação com Valores Pequenos:** Quando os valores reais são próximos de zero, mesmo pequenos erros absolutos podem gerar valores de MAPE extremamente grandes, distorcendo a avaliação geral do desempenho do modelo.28

#### **Mean Absolute Scaled Error (MASE)**

Proposto como uma alternativa robusta ao MAPE, o Erro Absoluto Médio Escalado contorna as principais desvantagens das métricas percentuais.

* Fórmula e Interpretação: O MASE escala o MAE do modelo de previsão dividindo-o pelo MAE de um modelo de benchmark simples (ingênuo):  
  MASE=MAEnaı¨ve​MAEmodelo​​=T−11​∑t=2T​∣Yt​−Yt−1​∣J1​∑j=1J​∣Yj​−Fj​∣​

  onde o denominador é o MAE da previsão ingênua de um passo à frente no conjunto de treinamento.36  
* **Interpretação:** A interpretação é relativa. Um valor de MASE \< 1 indica que o modelo proposto tem um desempenho melhor que o benchmark ingênuo. Um valor \> 1 indica que o modelo é pior que uma simples previsão do valor anterior.36  
* **Vantagens:** O MASE é independente de escala, como o MAPE, mas não sofre com os problemas de valores zero ou pequenos.36 É simétrico, penalizando erros positivos e negativos igualmente.36 Além disso, é aplicável a uma ampla gama de dados, incluindo séries temporais com tendência e sazonalidade, ajustando-se o modelo ingênuo de benchmark adequadamente.24  
* **Desvantagens:** Sua principal desvantagem reside na menor intuitividade para um público não técnico. Explicar o conceito de "erro absoluto médio escalado por um benchmark ingênuo" é mais complexo do que um simples "erro percentual médio".39

O MASE pode ser visto não apenas como uma métrica de erro, mas como uma medida do *valor agregado* do modelo. Qualquer instituição poderia usar um modelo ingênuo (por exemplo, a perda do próximo ano será a mesma deste ano) com custo zero de desenvolvimento. O investimento em equipes de modelagem, dados e sistemas só se justifica se os modelos complexos resultantes superarem essa abordagem simplista. Enquanto MAE e RMSE medem o erro absoluto, o MASE responde diretamente à pergunta de negócio: "Nosso modelo sofisticado justifica sua complexidade e custo?". Se o MASE for maior que 1, a resposta é não; o modelo está, na prática, adicionando mais ruído do que sinal em comparação com a alternativa mais simples. Isso posiciona o MASE como uma métrica de validação de negócio, útil para justificar a alocação de recursos e para descontinuar modelos que não demonstram um valor claro.

### **Tabela 1: Análise Comparativa das Métricas de Erro Centrais**

| Métrica | Fórmula | Interpretação Principal | Sensibilidade a Outliers | Vantagem-Chave | Desvantagem-Chave |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **MAE** | $(1/n) \\cdot \\sum | y \- \\hat{y} | $ | Erro médio absoluto na mesma unidade da variável-alvo. Minimiza para a mediana. | Baixa |
| **RMSE** | (1/n)⋅∑(y−y^​)2​ | Desvio padrão dos resíduos. Mesma unidade da variável-alvo. Minimiza para a média. | Alta | Penaliza fortemente erros grandes, alinhando-se com a aversão ao risco. Diferenciável. 20 | Pode ser inflado por um único outlier, mascarando o desempenho geral. 19 |
| **MAPE** | $(1/n) \\cdot \\sum( | y \- \\hat{y} | / | y | )$ |
| **MASE** | MAEmodelo​/MAEnaı¨ve​ | Erro relativo a um benchmark ingênuo. | Baixa | Independente de escala, simétrico e robusto a zeros. Mede o valor agregado do modelo. 36 | Menos intuitivo para stakeholders não técnicos do que o MAPE. 39 |

## **Parte II: Justificação e Aplicação na Validação de Modelos de Risco de Crédito**

A teoria das métricas de erro ganha vida quando aplicada aos desafios específicos de cada tipo de modelo de risco de crédito. A escolha da métrica primária de validação deve ser deliberada e justificada pelas características da variável-alvo e pelos objetivos de negócio do modelo.

### **Tabela 2: Métricas de Validação Primárias Recomendadas por Tipo de Modelo Financeiro**

| Modelo Financeiro | Característica-Chave da Variável | Métrica Primária de Calibração | Justificação | Métricas Secundárias / Complementares |
| :---- | :---- | :---- | :---- | :---- |
| **PD (Probabilidade de Inadimplência)** | Probabilidade (0, 1\) | **Brier Score** | Equivalente ao MSE para resultados binários; mede a precisão das probabilidades previstas e é uma regra de pontuação estritamente própria. 40 | Curva de Calibração, Teste de Hosmer-Lemeshow (com cautela), AUC/Gini (para discriminação). 42 |
| **LGD (Perda Dada a Inadimplência)** | Bimodal (picos em 0 e 1), contínua \[0,1+\] | **MAE** | Robusto à bimodalidade; foca na mediana, que é mais representativa que a média para distribuições com picos nos extremos. 44 | RMSE (para avaliar o impacto de grandes perdas), R², Análise de Correlação, Curvas de Captura de Perda. 1 |
| **EAD / CCF (Exposição na Inadimplência / Fator de Conversão de Crédito)** | EAD: Valor monetário. CCF: Bimodal \[0,1+\] | **MAE** (para CCF), **RMSE/MAE** (para EAD) | CCF tem distribuição similar à LGD.47 Para EAD direto, a escolha entre RMSE/MAE depende da função de perda de negócio. 48 | R², Análise de Correlação, Back-testing contra exposições realizadas. 1 |
| **Renda (Concessão, Estimação)** | Valor monetário, pode incluir zeros, escalas variadas | **MAPE / MASE** | MAPE para comparabilidade entre portfólios (com cautela).35 MASE como alternativa robusta que lida com zeros e não tem viés. 36 | MAE/RMSE (para avaliação dentro de um único portfólio). |

### **4\. Validando Modelos de Probabilidade de Inadimplência (PD)**

A validação de modelos de PD enfrenta um desafio duplo: avaliar a capacidade de **discriminação** e a precisão da **calibração**. A discriminação, frequentemente medida pela Área Sob a Curva ROC (AUC) ou pelo Coeficiente de Gini, avalia se o modelo consegue ordenar corretamente os inadimplentes como mais arriscados que os não inadimplentes.1 Embora crucial para o rank-ordering, a discriminação por si só é insuficiente. Para o cálculo de ECL e capital regulatório (RWA), a precisão da probabilidade prevista — a calibração — é fundamental.4 Um modelo pode ter um AUC perfeito e ainda assim estar mal calibrado, atribuindo sistematicamente probabilidades incorretas.

#### **Brier Score: O MSE para Probabilidades**

O Brier Score é a métrica de calibração por excelência para modelos de resultado binário.

* **Conceito e Relação com RMSE:** Matematicamente, o Brier Score é equivalente ao Mean Squared Error (MSE) quando o resultado observado (oi​) é binário (1 para inadimplência, 0 para adimplência) e a previsão (pi​) é uma probabilidade.40 A fórmula é:Brier=n1​i=1∑n​(pi​−oi​)2

  Consequentemente, o RMSE de um modelo de PD é simplesmente a raiz quadrada do Brier Score: RMSE=Brier​.40 Ele mede o desvio médio entre a probabilidade prevista e o resultado binário real.  
* **Justificativa de Uso:** O Brier Score é uma "regra de pontuação estritamente própria", o que significa que ele é matematicamente minimizado apenas quando as probabilidades previstas correspondem às probabilidades verdadeiras subjacentes.54 Ele combina de forma elegante a avaliação da calibração e da discriminação em uma única medida de desempenho geral, com valores mais baixos indicando um modelo melhor.40

#### **Ferramentas de Calibração Complementares**

* **Curvas de Calibração:** Estes gráficos são essenciais para a validação visual. Eles plotam a taxa de inadimplência observada contra a probabilidade de inadimplência prevista, geralmente agrupadas por decis de risco. Em um modelo perfeitamente calibrado, os pontos formam uma linha diagonal de 45 graus.42  
* **Teste de Hosmer-Lemeshow:** Este é um teste de bondade de ajuste que agrupa as observações por risco previsto e compara as contagens de inadimplência esperadas e observadas usando uma estatística qui-quadrado.1 No entanto, seu uso deve ser cauteloso, pois a comunidade estatística tem criticado sua dependência do número de grupos escolhidos e seu baixo poder estatístico para rejeitar modelos mal calibrados, não sendo mais recomendado como a principal ferramenta de avaliação de calibração.43

A utilidade do Brier Score vai além de um único número de erro. Ele pode ser decomposto em três componentes que oferecem insights de negócio acionáveis: Incerteza, Confiabilidade (Reliability) e Resolução (Resolution).41 A  
**Incerteza** representa a variabilidade inerente ao fenômeno (a taxa de inadimplência média do portfólio), definindo um "piso" de erro que nenhum modelo pode ultrapassar. A **Confiabilidade** mede a calibração do modelo; um erro de confiabilidade alto indica que as PDs previstas não correspondem às taxas de inadimplência reais (por exemplo, quando o modelo prevê 3% de PD, a taxa real é de 5%). A **Resolução** mede o poder de discriminação, ou seja, a capacidade do modelo de separar a população em segmentos com taxas de inadimplência distintas. Ao analisar essa decomposição, um validador pode diagnosticar a fonte do erro do modelo. Em vez de simplesmente reportar um Brier Score de 0.04, pode-se concluir que o erro se deve principalmente à baixa confiabilidade, apesar de uma boa resolução. Isso direciona a ação corretiva: o modelo discrimina bem, mas precisa ser recalibrado. Se a resolução for baixa, o modelo precisa de variáveis preditivas mais poderosas. Isso transforma a validação de um exercício de medição para um de diagnóstico.

### **5\. Validando Modelos de Loss Given Default (LGD)**

A validação de modelos LGD é notoriamente complexa devido à natureza única de sua variável-alvo.

* **O Desafio Crítico: A Distribuição Bimodal:** A característica mais proeminente e desafiadora da LGD é sua distribuição bimodal, com altas concentrações de observações em ou perto de 0% (indicando recuperação total ou "cura") e 100% (indicando perda total).44 Para tais distribuições, a média aritmética é uma medida de tendência central pobre e frequentemente enganosa, pois pode apontar para um valor que raramente ocorre na prática.44  
* **Por que RMSE Pode Ser Enganoso:** Como o RMSE é minimizado por modelos que preveem a média 23, um modelo LGD otimizado para RMSE tentará prever a LGD média do portfólio. Se a média for de 45%, mas quase nenhuma inadimplência real resulte em uma perda de 45%, o modelo estará sistematicamente errado para os resultados mais prováveis (0% e 100%). Isso é particularmente problemático para precificação de risco e alocação de capital em nível de empréstimo individual.  
* **A Vantagem do MAE:** O MAE, que é minimizado por modelos que preveem a mediana, é inerentemente mais robusto a essa bimodalidade.23 A mediana é uma medida de tendência central mais estável e representativa para distribuições bimodais ou fortemente assimétricas. Além disso, a menor sensibilidade do MAE a outliers é uma vantagem, dado que os custos de recuperação podem, em alguns casos, levar a valores de LGD superiores a 100%.61  
* **Métricas Alternativas e Benchmarking:** A validação de LGD deve ser multifacetada:  
  * **Modelos de Duas Etapas:** Uma prática comum é decompor o problema. Primeiro, um modelo de classificação (e.g., regressão logística) prevê a probabilidade de cura (LGD=0) versus não cura. Em seguida, um modelo de regressão prevê a LGD para o subconjunto de casos de não cura.62 A validação deve avaliar cada componente separadamente (e.g., Brier/AUC para o classificador, MAE/RMSE para o regressor) e o desempenho combinado.  
  * **Métricas de Rank-Ordering:** Em um ambiente de alta incerteza, a capacidade do modelo de pelo menos ordenar corretamente as perdas torna-se primordial. Métricas como a Taxa de Captura de Perda, a Razão de Acurácia Cumulativa (CLAR) e a correlação de postos de Spearman são cruciais para avaliar se o modelo distingue eficazmente entre empréstimos de alta e baixa perda, mesmo que a previsão pontual seja imprecisa.1  
  * **Benchmarks da Indústria:** Estudos de benchmarking em larga escala mostram consistentemente que os modelos LGD têm um poder explicativo limitado, com valores de R² frequentemente variando na faixa de 4% a 43%.46 É vital que os validadores comparem o desempenho de seus modelos com esses benchmarks publicados. Isso evita a rejeição de um modelo que é "bom" para os padrões da indústria simplesmente porque seu R² parece "baixo" em termos absolutos.

O desempenho preditivo geralmente baixo dos modelos LGD não é necessariamente uma falha dos algoritmos, mas sim um reflexo da qualidade e da natureza inerentemente ruidosa dos dados de recuperação. A coleta de dados de LGD é um desafio; o processo de recuperação pode levar anos, resultando em dados "censurados" (incompletos) para inadimplências recentes.67 Além disso, definições inconsistentes de "inadimplência" e a influência de fatores idiossincráticos não observáveis (como a habilidade de uma equipe de recuperação específica) introduzem um ruído substancial na variável LGD observada.68 Como resultado, mesmo o melhor modelo possível só consegue explicar uma pequena fração da variação da LGD.46 Diante dessa realidade, a validação de modelos LGD não deve se fixar em atingir um erro absoluto "baixo". Em vez disso, o foco deve ser no desempenho relativo (o modelo supera um benchmark simples, como a média histórica por segmento?), no poder de ordenação (o modelo consegue distinguir entre perdas altas e baixas?) e na estabilidade das previsões ao longo do tempo.

### **6\. Validando Modelos de Exposição na Inadimplência (EAD) e Fator de Conversão de Crédito (CCF)**

A modelagem de EAD para produtos com limites variáveis, como cartões de crédito e linhas de crédito rotativas, apresenta seus próprios desafios de validação.

* **Abordagens de Modelagem:** Existem duas abordagens principais:  
  1. **Modelo CCF (indireto):** Modela-se o Fator de Conversão de Crédito (CCF), que representa a proporção do limite não utilizado que se espera ser sacada no momento da inadimplência. O EAD é então derivado pela fórmula: EAD=SaldoAtual+(CCF×LimiteNa\~oUtilizado).47  
  2. **Modelo EAD Direto:** Modela-se diretamente o valor monetário do EAD.47  
* **Validação de Modelos CCF:** A distribuição empírica do CCF é frequentemente bimodal, com picos em 0 (nenhum saque adicional) e 1 (saque total do limite restante), assemelhando-se à distribuição da LGD.47 Por essa razão, a lógica de validação aplicada aos modelos LGD é diretamente transferível. O  
  **MAE** é geralmente a métrica de erro preferível ao RMSE para avaliar a precisão pontual dos modelos CCF, devido à sua robustez à distribuição não normal.75 As diretrizes regulatórias, como as da EBA, enfatizam a necessidade de garantir que o modelo CCF tenha poder discriminatório e seja bem calibrado, exigindo testes rigorosos out-of-sample e out-of-time para assegurar estabilidade e prevenir overfitting.77  
* **Validação de Modelos EAD Diretos:** Quando o EAD é modelado diretamente como um valor monetário, a escolha entre **RMSE e MAE** volta a ser uma decisão estratégica de negócio sobre a função de perda.48 Se grandes erros na previsão do valor da exposição são considerados desproporcionalmente caros (por exemplo, levando a uma subestimação crítica do capital necessário), o RMSE é a métrica mais apropriada. Se todos os erros monetários são ponderados de forma linear, o MAE é mais adequado.  
* **Métricas Complementares:** A validação de EAD e CCF deve ir além das métricas de erro pontual. O back-testing, que compara os EADs previstos com os EADs realizados em inadimplências reais, é uma ferramenta indispensável. Além disso, o benchmarking contra padrões regulatórios ou modelos mais simples fornece um contexto crucial para a avaliação do desempenho.48 Ferramentas visuais como gráficos de dispersão e matrizes de confusão também são valiosas para a análise qualitativa.1

A escolha entre modelar o EAD diretamente ou via CCF representa uma troca entre estabilidade estatística e intuição de negócio. A abordagem CCF é atraente porque normaliza a variável-alvo para uma proporção, o que pode ser estatisticamente mais estável e menos propenso a problemas de escala.72 No entanto, a fórmula do CCF,  
CCF=(EAD−Saldo)/(Limite−Saldo), possui um denominador que se aproxima de zero quando um cliente está perto de utilizar todo o seu limite. Isso torna o CCF calculado extremamente volátil e numericamente instável nesses cenários.76 A modelagem direta do EAD evita esse problema de instabilidade, mas enfrenta os desafios de modelar uma variável monetária com uma escala potencialmente muito ampla. Uma estrutura de validação robusta não deve apenas comparar o desempenho final do EAD previsto, mas também avaliar e justificar a abordagem de modelagem escolhida. Uma abordagem segmentada, que utiliza um modelo CCF para clientes com limites não utilizados significativos e um modelo EAD direto para clientes próximos ao limite, pode oferecer um equilíbrio superior.73 A validação deve testar e justificar essa escolha de segmentação, demonstrando que ela leva a um desempenho geral mais estável e preciso.

### **7\. Validando Modelos de Estimação e Concessão de Renda**

Modelos de estimação de renda são ferramentas críticas na subscrição de crédito, usadas para verificar a renda declarada ou para estimar a renda de candidatos com documentação limitada, como trabalhadores autônomos.80 A precisão desses modelos impacta diretamente o cálculo de rácios de endividamento (por exemplo, Debt-to-Income \- DTI), que são determinantes chave na decisão de aprovação do crédito.49

* **O Desafio da Comparabilidade e Escala:** As instituições financeiras operam em múltiplos mercados e atendem a segmentos de clientes com distribuições de renda vastamente diferentes. É essencial poder comparar o desempenho de um modelo de renda para um segmento de alta renda com o de um segmento de baixa renda, ou entre diferentes países.  
* **Justificativa para MAPE:** O **MAPE** é a métrica ideal para este tipo de benchmarking. Sua natureza percentual o torna independente da escala da variável renda.35 Um erro de 10% é interpretado da mesma forma, quer a renda média do portfólio seja de €20.000 ou €200.000. Isso permite que a gestão avalie e compare a eficácia relativa dos modelos entre diferentes portfólios de forma consistente.35  
* **Limitações do MAPE e o Papel do MASE:** Apesar de sua utilidade, o MAPE mantém suas desvantagens, como o problema da divisão por zero, que pode ser relevante em populações com trabalhadores informais ou desempregados com renda zero.28 O  
  **MASE** emerge como uma alternativa tecnicamente mais robusta. Ao comparar o MAE do modelo com o MAE de um benchmark ingênuo (por exemplo, a renda média do segmento), o MASE fornece uma medida de desempenho relativo e sem escala que é imune a zeros e não possui o viés de assimetria do MAPE.36 Embora menos intuitivo, é a escolha mais rigorosa para a validação formal e para justificar o valor agregado do modelo.  
* **Métricas Absolutas (MAE/RMSE):** Dentro de um único portfólio ou segmento homogêneo, **MAE** e **RMSE** continuam sendo ferramentas valiosas. O MAE informa o erro médio em unidades monetárias (por exemplo, euros), o que é útil para entender o impacto financeiro direto dos erros de estimativa. O RMSE pode ser empregado se a subestimação da renda para indivíduos de alta renda (o que levaria a grandes erros absolutos) for considerada particularmente arriscada, justificando uma penalidade maior para esses erros.

A validação de um modelo de renda não deve se limitar a medir o erro da estimativa em si. O objetivo final do modelo é melhorar a decisão de crédito. Portanto, a validação deve ser um processo de duas camadas. A primeira camada avalia a precisão da estimativa de renda usando métricas como MAPE ou MASE. A segunda camada, que é a mais importante do ponto de vista do negócio, avalia o impacto dessa precisão (ou imprecisão) nas métricas de risco do portfólio. Isso envolve a realização de análises de back-testing para responder a perguntas como: "Como as decisões de aprovação/rejeição teriam mudado se a renda real fosse usada em vez da renda estimada?". A análise deve quantificar o impacto nos principais resultados de negócio, como a taxa de inadimplência, a taxa de falsos positivos (rejeitar um bom cliente devido à subestimação da renda) e a taxa de falsos negativos (aprovar um mau cliente devido à superestimação da renda).83 Esta abordagem conecta diretamente a validação do modelo ao seu impacto financeiro e estratégico.

## **Parte III: Tópicos Avançados em Validação e Governança de Modelos**

### **8\. Uma Visão Geral das Técnicas de Modelagem**

A escolha da técnica de modelagem é um precursor da validação. A metodologia de validação deve ser apropriada para o tipo de modelo em questão, seja ele um modelo estatístico tradicional ou um algoritmo de machine learning mais complexo.

* **Modelos Estatísticos Tradicionais:**  
  * **Regressão Logística:** Continua a ser o benchmark da indústria para modelos de PD, valorizada por sua interpretabilidade e pela produção direta de saídas probabilísticas.4  
  * **Regressão Linear (OLS):** Frequentemente usada como ponto de partida para EAD ou LGD, mas suas suposições (e.g., normalidade dos resíduos) são muitas vezes violadas pela natureza limitada e não normal dessas variáveis.46  
  * **Modelos Tobit:** Projetados especificamente para variáveis-alvo censuradas (ou seja, limitadas em 0 e/ou 1), tornando-os uma escolha natural e superior à regressão linear para modelar LGD e CCF.8  
  * **Regressão Beta:** Uma abordagem ainda mais sofisticada que modela diretamente variáveis que são proporções no intervalo (0, 1). É teoricamente superior para LGD e CCF, pois modela a distribuição inteira (média e variância), não apenas a média, e pode lidar com a heterocedasticidade.63 Variantes como a regressão beta inflacionada em zero e um (Zero-and-One-Inflated Beta) são ainda mais adequadas para capturar os picos em 0 e 1, característicos das distribuições de LGD e CCF.89  
* **Modelos de Machine Learning (ML):**  
  * **Árvores de Decisão e Random Forests:** Modelos não paramétricos que capturam nativamente interações não lineares entre variáveis. Random Forests, por serem um ensemble de árvores, são mais robustos ao overfitting.4  
  * **Gradient Boosting (e.g., XGBoost, LightGBM):** Frequentemente os modelos com o melhor desempenho preditivo em dados tabulares, como os encontrados em risco de crédito.4 Eles constroem árvores de decisão de forma sequencial, onde cada nova árvore é treinada para corrigir os erros residuais da anterior. Embora extremamente poderosos, podem ser propensos a overfitting se não forem regularizados corretamente e são inerentemente menos interpretáveis.84  
  * **Redes Neurais (Deep Learning):** Capazes de modelar relações de altíssima complexidade, mas exigem grandes volumes de dados para treinamento e são as mais difíceis de interpretar ("caixas-pretas"), o que representa um desafio significativo para a conformidade regulatória.4  
* **O Mandato da Interpretabilidade (Explainable AI \- XAI):** A crescente adoção de modelos de ML complexos no setor financeiro foi acompanhada por uma demanda igualmente crescente por transparência por parte dos reguladores e auditores. É imperativo que as instituições possam explicar como seus modelos chegam a uma decisão.95 Ferramentas de XAI, como SHAP (SHapley Additive exPlanations) e LIME (Local Interpretable Model-agnostic Explanations), foram desenvolvidas para fornecer essa transparência. Elas podem gerar interpretações locais (explicando por que um cliente específico recebeu um determinado score) e globais (identificando as variáveis mais importantes para o modelo como um todo).95 A validação de um modelo de ML deve, portanto, incluir uma avaliação da plausibilidade e estabilidade de suas explicações XAI.

A dicotomia histórica entre modelos tradicionais (interpretáveis, mas menos potentes) e modelos de ML (potentes, mas opacos) está se dissolvendo. O avanço das técnicas de XAI está efetivamente "abrindo a caixa-preta", permitindo que as instituições aproveitem o poder preditivo superior do ML sem sacrificar a transparência exigida pelos reguladores e pela boa governança. A validação de modelos evoluiu em conformidade. Não basta mais verificar o RMSE ou o Brier Score. O validador agora tem a responsabilidade de verificar se as explicações geradas por ferramentas como o SHAP são estáveis e conceitualmente sólidas. Por exemplo, se um modelo de LGD, conforme interpretado pelo SHAP, indica que um maior Loan-to-Value (LTV) *diminui* a perda prevista, o modelo seria sinalizado como conceitualmente falho e inaceitável para uso, mesmo que seu MAE fosse baixo. A validação moderna de modelos de ML em risco de crédito repousa sobre três pilares: **Desempenho** (métricas de erro), **Robustez** (estabilidade, back-testing) e **Interpretabilidade** (validação das saídas XAI). A escolha do modelo ideal não é mais sobre qual tem o menor erro, mas qual oferece o melhor e mais defensável equilíbrio entre esses três pilares.

### **9\. Uma Estrutura Holística de Validação de Modelos**

Uma validação eficaz vai além da seleção de métricas e modelos. Ela deve ser integrada em uma estrutura de governança robusta que inclua monitoramento contínuo, análise de sensibilidade e testes em ambiente real.

* **Back-testing e Monitoramento Contínuo:** A validação não é um evento estático realizado apenas no desenvolvimento do modelo. O monitoramento contínuo é um processo dinâmico que compara as previsões do modelo com os resultados reais à medida que novos dados se tornam disponíveis.1 As políticas de gestão de risco do modelo devem definir limiares claros (por exemplo, um desvio de 10% no RMSE por dois trimestres consecutivos) que atuem como  
  **gatilhos para recalibração** ou redesenvolvimento.99 A orientação supervisória, como a SR 11-7, exige relatórios de monitoramento frequentes (por exemplo, trimestrais) que cubram uma ampla gama de métricas de desempenho e estabilidade.101  
* **O Impacto das Previsões Macroeconômicas:** Os modelos IFRS 9 são, por concepção, sensíveis a variáveis macroeconômicas (MEVs) como PIB, desemprego e taxas de juros.7 Uma parte significativa do erro de previsão do ECL não se origina de deficiências nos modelos de risco (PD, LGD, EAD), mas de erros nas próprias previsões macroeconômicas usadas como input.16 A volatilidade econômica inesperada, como a observada durante a pandemia de COVID-19, demonstrou como as previsões de ECL podem ser instáveis devido a choques nos MEVs.7 Portanto, a validação deve incluir análises de sensibilidade robustas para entender como as previsões de ECL se comportam sob diferentes cenários econômicos. Além disso, é crucial avaliar a precisão das próprias previsões macroeconômicas, comparando-as com os resultados reais para identificar vieses sistemáticos.102  
* **A Estrutura Campeão-Desafiante (Champion-Challenger):** Esta é uma estrutura de validação dinâmica e de baixo risco. Em vez de substituir um modelo de produção (o "Campeão") de uma só vez, um novo modelo (o "Desafiante") é testado em paralelo, recebendo uma pequena porção do tráfego de decisões em tempo real.103 Isso permite uma comparação direta do desempenho em um ambiente real, avaliando não apenas métricas estatísticas (como AUC), mas também métricas de negócio (como taxas de inadimplência, taxas de aprovação e lucratividade).103 Se o Desafiante superar consistentemente o Campeão em métricas de negócio chave, ele é promovido a novo Campeão, e um novo Desafiante pode ser introduzido. Este ciclo de teste contínuo fomenta a melhoria e validação iterativa dos modelos.104

A validação do ECL agregado deve evoluir de um simples back-testing de ECL\_previsto vs. ECL\_realizado para uma **análise de atribuição de erro**. O erro total na previsão do ECL, que é uma função de PD, LGD e EAD, não é a simples soma dos erros de seus componentes. As correlações entre esses parâmetros de risco, especialmente em cenários de estresse (o chamado "wrong-way risk", onde a PD aumenta ao mesmo tempo que a LGD e a EAD), desempenham um papel crucial na determinação da perda final.8 Um grande erro no ECL agregado pode não ser informativo o suficiente. A validação avançada, possivelmente usando simulação de Monte Carlo ou técnicas de decomposição de variância, deve tentar responder a perguntas mais profundas: Qual a contribuição da variância do erro do modelo de PD para a variância total do erro do ECL? Qual a contribuição da covariância entre os erros de PD e LGD? Se o modelo não captura adequadamente a correlação positiva entre PD e LGD, ele subestimará sistematicamente o ECL em cenários de estresse. Esta abordagem permite que a instituição identifique e corrija a fonte mais significativa de risco do modelo, em vez de tentar ajustar todos os componentes simultaneamente.

### **10\. Recomendações Estratégicas e Conclusão**

A validação de modelos de risco de crédito é uma disciplina que exige rigor técnico, julgamento de negócio e conformidade regulatória. As seguintes recomendações estratégicas podem guiar as instituições para uma estrutura de validação mais robusta e defensável.

* **Adotar uma Abordagem Multimétrica:** A validação nunca deve se basear em uma única métrica. Um painel de controle de métricas, incluindo medidas de erro (MAE/RMSE), de ordenação (AUC/Gini/CLAR) e de calibração (Brier Score, Curvas de Calibração), deve ser utilizado e reportado. A escolha do conjunto de métricas para cada modelo deve ser deliberada e justificada com base nas características da variável-alvo e nos objetivos de negócio.  
* **Documentação é Defesa:** Cada escolha metodológica — da seleção da métrica à arquitetura do modelo e suas suposições — deve ser rigorosamente documentada.1 O relatório de validação deve ser um documento autônomo e defensável, explicando  
  *por que* o MAE foi preferido ao RMSE para o modelo LGD (citando a bimodalidade da distribuição) e *por que* um modelo de Gradient Boosting foi considerado aceitável (detalhando as ferramentas XAI usadas para garantir interpretabilidade). Esta documentação é a principal linha de defesa em uma auditoria ou revisão regulatória.  
* **Contextualizar o Desempenho:** Os resultados das métricas devem ser sempre interpretados dentro de um contexto. Um valor de R² de 40% para um modelo LGD pode ser excelente, enquanto o mesmo valor para um modelo EAD em um portfólio simples pode ser medíocre. O uso de **benchmarks da indústria** 46 e benchmarks internos (modelos mais simples, versão anterior do modelo) é essencial para uma avaliação justa e para definir expectativas realistas de desempenho.

Em conclusão, a seleção e justificação de métricas de erro não é um mero apêndice técnico da modelagem de risco, mas sim o cerne da governança de modelos. Ela reflete a compreensão da instituição sobre a natureza de seus riscos, sua tolerância a diferentes tipos de erro e sua capacidade de defender suas abordagens para stakeholders internos e externos. Uma estrutura de validação bem-sucedida é aquela que é precisa, robusta, transparente e, acima de tudo, defensável.

### **Tabela 3: Benchmarks de Desempenho de Modelos LGD (Ilustrativo)**

| Métrica | Faixa de Desempenho Típica (Corporativo) | Faixa de Desempenho Típica (Varejo) | Fontes |
| :---- | :---- | :---- | :---- |
| **R² (Coeficiente de Determinação)** | 4% \- 43% | Geralmente mais baixo que o corporativo | 46 |
| **RMSE (Root Mean Squared Error)** | \~0.25 | \~0.29 | 45 |
| **MAE (Mean Absolute Error)** | \~0.17 | \~0.18 | 45 |
| **Accuracy Ratio / CLAR** | \> 75% (considerado "bom") | Varia, mas benchmarks em torno de 50-80% são discutidos | 65 |

#### **Referências citadas**

1. Blog\_2016\_14 \- Model Risk Management under IFRS 9 \- Aptivaa, acessado em julho 15, 2025, [https://aptivaa.com/pdf/ifrs9-model-risk-management-1594098423-1.pdf](https://aptivaa.com/pdf/ifrs9-model-risk-management-1594098423-1.pdf)  
2. Model Risk Management, Comptroller's Handbook, acessado em julho 15, 2025, [https://www.occ.treas.gov/publications-and-resources/publications/comptrollers-handbook/files/model-risk-management/pub-ch-model-risk.pdf](https://www.occ.treas.gov/publications-and-resources/publications/comptrollers-handbook/files/model-risk-management/pub-ch-model-risk.pdf)  
3. SR 11-7 attachment: Supervisory Guidance on Model Risk Management \- Federal Reserve Board, acessado em julho 15, 2025, [https://www.federalreserve.gov/supervisionreg/srletters/sr1107a1.pdf](https://www.federalreserve.gov/supervisionreg/srletters/sr1107a1.pdf)  
4. Predicting Probability of Default Under IFRS 9 \- DiVA, acessado em julho 15, 2025, [http://kth.diva-portal.org/smash/get/diva2:1964001/FULLTEXT01.pdf](http://kth.diva-portal.org/smash/get/diva2:1964001/FULLTEXT01.pdf)  
5. IFRS 9 Expected Loss Model Validation \- Finalyse, acessado em julho 15, 2025, [https://www.finalyse.com/blog/ifrs-9-expected-loss-model-validation](https://www.finalyse.com/blog/ifrs-9-expected-loss-model-validation)  
6. IFRS 9 2023 Monitoring Report \- European Banking Authority, acessado em julho 15, 2025, [https://www.eba.europa.eu/sites/default/files/2023-11/25b12d35-9c28-4335-a589-166c77198920/Final%20Report%20on%20IFRS9%20implementation%20by%20EU%20institutions.pdf](https://www.eba.europa.eu/sites/default/files/2023-11/25b12d35-9c28-4335-a589-166c77198920/Final%20Report%20on%20IFRS9%20implementation%20by%20EU%20institutions.pdf)  
7. IFRS 9 Impairment explained: Challenges and solutions for 2021 and beyond \- Experian UK, acessado em julho 15, 2025, [https://www.experian.co.uk/blogs/latest-thinking/risk-analytics/ifrs-9-impairment-explained-challenges-and-solutions-for-2021-and-beyond/](https://www.experian.co.uk/blogs/latest-thinking/risk-analytics/ifrs-9-impairment-explained-challenges-and-solutions-for-2021-and-beyond/)  
8. Point-In-Time (PIT) LGD and EAD Models for IFRS9 ... \- Z-Risk Engine, acessado em julho 15, 2025, [https://www.z-riskengine.com/media/xfylthf4/pit-lgd-paper-chawla-forest-aguais-re-submitted-to-journal-v3-for-web.pdf](https://www.z-riskengine.com/media/xfylthf4/pit-lgd-paper-chawla-forest-aguais-re-submitted-to-journal-v3-for-web.pdf)  
9. Expected Credit Loss (ECL) \- KPMG agentic corporate services, acessado em julho 15, 2025, [https://assets.kpmg.com/content/dam/kpmgsites/in/pdf/2025/01/expected-credit-loss-ecl.pdf](https://assets.kpmg.com/content/dam/kpmgsites/in/pdf/2025/01/expected-credit-loss-ecl.pdf)  
10. IFRS 9 governance \- KPMG International, acessado em julho 15, 2025, [https://assets.kpmg.com/content/dam/kpmg/is/pdf/2016/10/IFRS%209/4\_Steven%20Hall.pdf](https://assets.kpmg.com/content/dam/kpmg/is/pdf/2016/10/IFRS%209/4_Steven%20Hall.pdf)  
11. SUPERVISORY HANDBOOK \- European Banking Authority, acessado em julho 15, 2025, [https://www.eba.europa.eu/sites/default/files/document\_library/Publications/Reports/2023/1061495/Supervisory%20handbook%20on%20the%20validation%20of%20IRB%20rating%20systems%20revised.pdf](https://www.eba.europa.eu/sites/default/files/document_library/Publications/Reports/2023/1061495/Supervisory%20handbook%20on%20the%20validation%20of%20IRB%20rating%20systems%20revised.pdf)  
12. Sound Practices for Model Risk Management: Supervisory Guidance on Model Risk Management \- Office of the Comptroller of the Currency (OCC), acessado em julho 15, 2025, [https://www.occ.gov/news-issuances/bulletins/2011/bulletin-2011-12.html](https://www.occ.gov/news-issuances/bulletins/2011/bulletin-2011-12.html)  
13. Risk Management & Modelling \- PwC, acessado em julho 15, 2025, [https://www.pwc.com/cz/cs/assets/Risk-management-and-Modelling-eBook-A4.pdf](https://www.pwc.com/cz/cs/assets/Risk-management-and-Modelling-eBook-A4.pdf)  
14. The evolution of model risk management | McKinsey, acessado em julho 15, 2025, [https://www.mckinsey.com/capabilities/risk-and-resilience/our-insights/the-evolution-of-model-risk-management](https://www.mckinsey.com/capabilities/risk-and-resilience/our-insights/the-evolution-of-model-risk-management)  
15. Demystifying Expected Credit Loss (ECL) \- KPMG agentic corporate services, acessado em julho 15, 2025, [https://assets.kpmg.com/content/dam/kpmg/in/pdf/2017/07/Demystifying-Expected-Credit-Loss.pdf](https://assets.kpmg.com/content/dam/kpmg/in/pdf/2017/07/Demystifying-Expected-Credit-Loss.pdf)  
16. CECL, IFRS 9 and the Demand for Forecast Stability \- GARP, acessado em julho 15, 2025, [https://www.garp.org/risk-intelligence/culture-governance/cecl-ifrs-9-and-the-demand-for-forecast-stability](https://www.garp.org/risk-intelligence/culture-governance/cecl-ifrs-9-and-the-demand-for-forecast-stability)  
17. The Timeliness of Accounting Write‐Downs by U.S. Financial Institutions During the Financial Crisis of 2007–2008 \- ResearchGate, acessado em julho 15, 2025, [https://www.researchgate.net/publication/227770201\_The\_Timeliness\_of\_Accounting\_Write-Downs\_by\_US\_Financial\_Institutions\_During\_the\_Financial\_Crisis\_of\_2007-2008](https://www.researchgate.net/publication/227770201_The_Timeliness_of_Accounting_Write-Downs_by_US_Financial_Institutions_During_the_Financial_Crisis_of_2007-2008)  
18. Mean Absolute Error \- Soulpage IT Solutions, acessado em julho 15, 2025, [https://soulpageit.com/ai-glossary/mean-absolute-error-explained/](https://soulpageit.com/ai-glossary/mean-absolute-error-explained/)  
19. Introduction to Evaluating Regression Models \- Analytics Vidhya, acessado em julho 15, 2025, [https://www.analyticsvidhya.com/blog/2021/10/evaluation-metric-for-regression-models/](https://www.analyticsvidhya.com/blog/2021/10/evaluation-metric-for-regression-models/)  
20. Choosing between MAE, MSE and RMSE \- Hugo Matalonga, acessado em julho 15, 2025, [https://hmatalonga.com/blog/choosing-between-mae-mse-and-rmse/](https://hmatalonga.com/blog/choosing-between-mae-mse-and-rmse/)  
21. MAE (mean absolute error) In Machine Learning ? | by Muhammad Hassan | Medium, acessado em julho 15, 2025, [https://medium.com/@muhammadhassan1762005/mae-mean-absolute-error-in-machine-learning-e678cc7bb8d4](https://medium.com/@muhammadhassan1762005/mae-mean-absolute-error-in-machine-learning-e678cc7bb8d4)  
22. Essential Regression Evaluation Metrics: MSE, RMSE, MAE, R², and Adjusted R², acessado em julho 15, 2025, [https://farshadabdulazeez.medium.com/essential-regression-evaluation-metrics-mse-rmse-mae-r%C2%B2-and-adjusted-r%C2%B2-0600daa1c03a](https://farshadabdulazeez.medium.com/essential-regression-evaluation-metrics-mse-rmse-mae-r%C2%B2-and-adjusted-r%C2%B2-0600daa1c03a)  
23. \[Q\] Can anyone explain the advantages/disadvantages between the various regression error metrics? (e.g. RMSE, MPE, MAE etc.) : r/statistics \- Reddit, acessado em julho 15, 2025, [https://www.reddit.com/r/statistics/comments/ll4rvm/q\_can\_anyone\_explain\_the\_advantagesdisadvantages/](https://www.reddit.com/r/statistics/comments/ll4rvm/q_can_anyone_explain_the_advantagesdisadvantages/)  
24. 5.8 Evaluating point forecast accuracy | Forecasting: Principles and Practice (3rd ed), acessado em julho 15, 2025, [https://otexts.com/fpp3/accuracy.html](https://otexts.com/fpp3/accuracy.html)  
25. Unlocking the Power of RMSE \- Number Analytics, acessado em julho 15, 2025, [https://www.numberanalytics.com/blog/rmse-for-machine-learning-practitioners](https://www.numberanalytics.com/blog/rmse-for-machine-learning-practitioners)  
26. Mean Squared Error or R-Squared \- Which one to use? \- Analytics Yogi, acessado em julho 15, 2025, [https://vitalflux.com/mean-square-error-r-squared-which-one-to-use/](https://vitalflux.com/mean-square-error-r-squared-which-one-to-use/)  
27. All about loss functions like MSE, MAE, RMSE etc | by Abhishek Jain \- Medium, acessado em julho 15, 2025, [https://medium.com/@abhishekjainindore24/all-about-loss-functions-like-mse-mae-rmse-etc-36596e3802f5](https://medium.com/@abhishekjainindore24/all-about-loss-functions-like-mse-mae-rmse-etc-36596e3802f5)  
28. Mean Absolute Percentage Error (MAPE): What You Need To Know \- Arize AI, acessado em julho 15, 2025, [https://arize.com/blog-course/mean-absolute-percentage-error-mape-what-you-need-to-know/](https://arize.com/blog-course/mean-absolute-percentage-error-mape-what-you-need-to-know/)  
29. Learn Mean Absolute Percentage Error | Vexpower, acessado em julho 15, 2025, [https://www.vexpower.com/brief/mean-absolute-percentage-error](https://www.vexpower.com/brief/mean-absolute-percentage-error)  
30. A Comprehensive Guide to Mean Absolute Percentage Error (MAPE) \- Coralogix, acessado em julho 15, 2025, [https://coralogix.com/ai-blog/a-comprehensive-guide-to-mean-absolute-percentage-error-mape/](https://coralogix.com/ai-blog/a-comprehensive-guide-to-mean-absolute-percentage-error-mape/)  
31. Mean Absolute Percent Error \- C3 AI, acessado em julho 15, 2025, [https://c3.ai/glossary/data-science/mean-absolute-percent-error/](https://c3.ai/glossary/data-science/mean-absolute-percent-error/)  
32. 3.4 Evaluating forecast accuracy | Forecasting: Principles and Practice (2nd ed) \- OTexts, acessado em julho 15, 2025, [https://otexts.com/fpp2/accuracy.html](https://otexts.com/fpp2/accuracy.html)  
33. What are the shortcomings of the Mean Absolute Percentage Error (MAPE)?, acessado em julho 15, 2025, [https://stats.stackexchange.com/questions/299712/what-are-the-shortcomings-of-the-mean-absolute-percentage-error-mape](https://stats.stackexchange.com/questions/299712/what-are-the-shortcomings-of-the-mean-absolute-percentage-error-mape)  
34. Interpreting Mean Absolute Percentage Error Results \- FasterCapital, acessado em julho 15, 2025, [https://fastercapital.com/topics/interpreting-mean-absolute-percentage-error-results.html/1](https://fastercapital.com/topics/interpreting-mean-absolute-percentage-error-results.html/1)  
35. MAPE vs MAE: Which Metric is Better? | by Lauren Gilbert | Trusted Data Science @ Haleon, acessado em julho 15, 2025, [https://medium.com/trusted-data-science-haleon/mape-vs-mae-which-metric-is-better-68dd559cbfb1](https://medium.com/trusted-data-science-haleon/mape-vs-mae-which-metric-is-better-68dd559cbfb1)  
36. Mean absolute scaled error \- Wikipedia, acessado em julho 15, 2025, [https://en.wikipedia.org/wiki/Mean\_absolute\_scaled\_error](https://en.wikipedia.org/wiki/Mean_absolute_scaled_error)  
37. A note on the Mean Absolute Scaled Error \- ResearchGate, acessado em julho 15, 2025, [https://www.researchgate.net/publication/281334375\_A\_note\_on\_the\_Mean\_Absolute\_Scaled\_Error](https://www.researchgate.net/publication/281334375_A_note_on_the_Mean_Absolute_Scaled_Error)  
38. ANOTHER LOOK AT FORECAST-ACCURACY METRICS FOR INTERMITTENT DEMAND \- Rob J Hyndman, acessado em julho 15, 2025, [https://robjhyndman.com/papers/foresight.pdf](https://robjhyndman.com/papers/foresight.pdf)  
39. 2.1 Measuring accuracy of point forecasts | Forecasting and Analytics with the Augmented Dynamic Adaptive Model (ADAM), acessado em julho 15, 2025, [https://openforecast.org/adam/errorMeasures.html](https://openforecast.org/adam/errorMeasures.html)  
40. ema/15-Model-performance.Rmd at master · pbiecek/ema · GitHub, acessado em julho 15, 2025, [https://github.com/pbiecek/ema/blob/master/15-Model-performance.Rmd](https://github.com/pbiecek/ema/blob/master/15-Model-performance.Rmd)  
41. Brier score \- Wikipedia, acessado em julho 15, 2025, [https://en.wikipedia.org/wiki/Brier\_score](https://en.wikipedia.org/wiki/Brier_score)  
42. Evaluation Metrics For Credit Risk Classification Models \- FasterCapital, acessado em julho 15, 2025, [https://fastercapital.com/topics/evaluation-metrics-for-credit-risk-classification-models.html/1](https://fastercapital.com/topics/evaluation-metrics-for-credit-risk-classification-models.html/1)  
43. Multivariate Classification Rules: Calibration and Discrimination | Request PDF, acessado em julho 15, 2025, [https://www.researchgate.net/publication/229676605\_Multivariate\_Classification\_Rules\_Calibration\_and\_Discrimination](https://www.researchgate.net/publication/229676605_Multivariate_Classification_Rules_Calibration_and_Discrimination)  
44. Weighted Quantile Regression Forests for Bimodal Distribution ..., acessado em julho 15, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC7517045/](https://pmc.ncbi.nlm.nih.gov/articles/PMC7517045/)  
45. Underperforming performance measures? A review of measures for loss given default models \- Journal of Risk Model Validation \- Risk.net, acessado em julho 15, 2025, [https://www.risk.net/journal-of-risk-model-validation/5462081/underperforming-performance-measures-a-review-of-measures-for-loss-given-default-models](https://www.risk.net/journal-of-risk-model-validation/5462081/underperforming-performance-measures-a-review-of-measures-for-loss-given-default-models)  
46. A proposed framework for backtesting loss given default models \- ePrints Soton \- University of Southampton, acessado em julho 15, 2025, [https://eprints.soton.ac.uk/386766/1/A\_proposed\_framework.pdf](https://eprints.soton.ac.uk/386766/1/A_proposed_framework.pdf)  
47. Exposure at default models with and without the credit conversion factor \- ResearchGate, acessado em julho 15, 2025, [https://www.researchgate.net/publication/295161153\_Exposure\_at\_default\_models\_with\_and\_without\_the\_credit\_conversion\_factor](https://www.researchgate.net/publication/295161153_Exposure_at_default_models_with_and_without_the_credit_conversion_factor)  
48. The Ultimate EAD Risk Management & Modeling Guide \- Number Analytics, acessado em julho 15, 2025, [https://www.numberanalytics.com/blog/ead-risk-management-modeling-guide](https://www.numberanalytics.com/blog/ead-risk-management-modeling-guide)  
49. Validating a Credit Score Model in Conjunction with Additional Underwriting Criteria \- VantageScore, acessado em julho 15, 2025, [https://cdn.vantagescore.com/uploads/2022/02/Validation\_with\_Overlay.pdf](https://cdn.vantagescore.com/uploads/2022/02/Validation_with_Overlay.pdf)  
50. A Brief on Brier Scores | UVA Library, acessado em julho 15, 2025, [https://library.virginia.edu/data/articles/a-brief-on-brier-scores](https://library.virginia.edu/data/articles/a-brief-on-brier-scores)  
51. 3\. Metrics \- Risk Practitioner Handbook, acessado em julho 15, 2025, [https://risk-practitioner.com/chapter3/chapter3](https://risk-practitioner.com/chapter3/chapter3)  
52. (PDF) On misconceptions about the Brier score in binary prediction models \- ResearchGate, acessado em julho 15, 2025, [https://www.researchgate.net/publication/390570464\_On\_misconceptions\_about\_the\_Brier\_score\_in\_binary\_prediction\_models](https://www.researchgate.net/publication/390570464_On_misconceptions_about_the_Brier_score_in_binary_prediction_models)  
53. Evaluating the predictive performance of malaria antibodies and FCGR3B gene polymorphisms on Plasmodium falciparum infection outcome: a prospective cohort study \- PMC, acessado em julho 15, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC7450914/](https://pmc.ncbi.nlm.nih.gov/articles/PMC7450914/)  
54. On misconceptions about the Brier score in binary prediction models \- arXiv, acessado em julho 15, 2025, [https://arxiv.org/html/2504.04906v4](https://arxiv.org/html/2504.04906v4)  
55. On misconceptions about the Brier score in binary prediction models \- arXiv, acessado em julho 15, 2025, [https://arxiv.org/html/2504.04906v3](https://arxiv.org/html/2504.04906v3)  
56. Proof: Brier scoring rule is strictly proper scoring rule \- The Book of Statistical Proofs, acessado em julho 15, 2025, [https://statproofbook.github.io/P/bsr-spsr.html](https://statproofbook.github.io/P/bsr-spsr.html)  
57. Brier Score: Understanding Model Calibration \- neptune.ai, acessado em julho 15, 2025, [https://neptune.ai/blog/brier-score-and-model-calibration](https://neptune.ai/blog/brier-score-and-model-calibration)  
58. Evaluation of clinical prediction models (part 2): how to undertake an external validation study | The BMJ, acessado em julho 15, 2025, [https://www.bmj.com/content/384/bmj-2023-074820](https://www.bmj.com/content/384/bmj-2023-074820)  
59. Benchmarking regression algorithms for loss given default modeling \- ResearchGate, acessado em julho 15, 2025, [https://www.researchgate.net/publication/313310986\_Benchmarking\_regression\_algorithms\_for\_loss\_given\_default\_modeling](https://www.researchgate.net/publication/313310986_Benchmarking_regression_algorithms_for_loss_given_default_modeling)  
60. From Power Curves to Discriminative Power: Measuring Model Performance of LGD Models, acessado em julho 15, 2025, [https://www.scirp.org/journal/paperinformation?paperid=77835](https://www.scirp.org/journal/paperinformation?paperid=77835)  
61. Internal Risk Components Validation: Indicative Benchmarking of Discriminatory Power for LGD Models (Public Version), acessado em julho 15, 2025, [https://essay.utwente.nl/71977/2/Sproates\_MA\_BMS.pdf](https://essay.utwente.nl/71977/2/Sproates_MA_BMS.pdf)  
62. Challenging LGD models with Machine Learning \- Mathematics \- Vrije Universiteit Amsterdam, acessado em julho 15, 2025, [https://www.math.vu.nl/\~sbhulai/papers/thesis-severeijns.pdf](https://www.math.vu.nl/~sbhulai/papers/thesis-severeijns.pdf)  
63. Overview of Loss Given Default Models \- MATLAB & Simulink \- MathWorks, acessado em julho 15, 2025, [https://www.mathworks.com/help/risk/overview-of-loss-given-default.html](https://www.mathworks.com/help/risk/overview-of-loss-given-default.html)  
64. allmeidaapedro/Lending-Club-Credit-Scoring: In this project, I estimate the PD, EAD and LGD to compute the Expected Loss (EL \= PD\*EAD\*LGD) and design a credit policy on Lending Club's loans. \- GitHub, acessado em julho 15, 2025, [https://github.com/allmeidaapedro/Lending-Club-Credit-Scoring](https://github.com/allmeidaapedro/Lending-Club-Credit-Scoring)  
65. Assessing the discriminatory power of loss given default models \- PMC \- PubMed Central, acessado em julho 15, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC9225220/](https://pmc.ncbi.nlm.nih.gov/articles/PMC9225220/)  
66. A Framework for LGD Validation of Retail Portfolios \- OVGU, acessado em julho 15, 2025, [https://www.fww.ovgu.de/fww\_media/femm/femm\_2009/2009\_25.pdf](https://www.fww.ovgu.de/fww_media/femm/femm_2009/2009_25.pdf)  
67. The Challenges And Limitations Of Loss Given Default Estimation And How To Overcome Them \- FasterCapital, acessado em julho 15, 2025, [https://fastercapital.com/topics/the-challenges-and-limitations-of-loss-given-default-estimation-and-how-to-overcome-them.html](https://fastercapital.com/topics/the-challenges-and-limitations-of-loss-given-default-estimation-and-how-to-overcome-them.html)  
68. Probability of Default: Definition, Factors, and Calculation \- Abrigo, acessado em julho 15, 2025, [https://www.abrigo.com/blog/blog-probability-of-default/](https://www.abrigo.com/blog/blog-probability-of-default/)  
69. Response to consultation on Guidelines PD estimation, LGD estimation and treatment of defaulted assets | European Banking Authority, acessado em julho 15, 2025, [https://www.eba.europa.eu/eba-response/8344](https://www.eba.europa.eu/eba-response/8344)  
70. Credit conversion factor \- Wikipedia, acessado em julho 15, 2025, [https://en.wikipedia.org/wiki/Credit\_conversion\_factor](https://en.wikipedia.org/wiki/Credit_conversion_factor)  
71. Understanding Exposure at Default \- Aspect Advisory's, acessado em julho 15, 2025, [https://www.aspectadvisory.eu/exposure-at-default/](https://www.aspectadvisory.eu/exposure-at-default/)  
72. Comparison of Predictive Accuracy of Alternative LEQ Models and Methods | Download Table \- ResearchGate, acessado em julho 15, 2025, [https://www.researchgate.net/figure/Comparison-of-Predictive-Accuracy-of-Alternative-LEQ-Models-and-Methods\_tbl7\_228423877](https://www.researchgate.net/figure/Comparison-of-Predictive-Accuracy-of-Alternative-LEQ-Models-and-Methods_tbl7_228423877)  
73. Exposure at default models with and without the credit conversion factor \- IDEAS/RePEc, acessado em julho 15, 2025, [https://ideas.repec.org/a/eee/ejores/v252y2016i3p910-920.html](https://ideas.repec.org/a/eee/ejores/v252y2016i3p910-920.html)  
74. Statistical and machine learning for credit and market risk management, acessado em julho 15, 2025, [https://epub.uni-regensburg.de/51522/1/Dissertation\_Online.pdf](https://epub.uni-regensburg.de/51522/1/Dissertation_Online.pdf)  
75. Models and forecasts of credit card balance \- CORE, acessado em julho 15, 2025, [https://core.ac.uk/download/pdf/77009321.pdf](https://core.ac.uk/download/pdf/77009321.pdf)  
76. Modeling Exposure at Default, Credit Conversion Factors and the Basel II Accord | Request PDF \- ResearchGate, acessado em julho 15, 2025, [https://www.researchgate.net/publication/288346183\_Modeling\_Exposure\_at\_Default\_Credit\_Conversion\_Factors\_and\_the\_Basel\_II\_Accord](https://www.researchgate.net/publication/288346183_Modeling_Exposure_at_Default_Credit_Conversion_Factors_and_the_Basel_II_Accord)  
77. Consultation paper \- European Banking Authority, acessado em julho 15, 2025, [https://www.eba.europa.eu/sites/default/files/2025-07/b3f9af47-ab61-4e89-94f2-7910c39c372f/Consultation%20paper%20Guidelines%20CCF.pdf](https://www.eba.europa.eu/sites/default/files/2025-07/b3f9af47-ab61-4e89-94f2-7910c39c372f/Consultation%20paper%20Guidelines%20CCF.pdf)  
78. The Ultimate Guide to Exposure at Default Basics \- Number Analytics, acessado em julho 15, 2025, [https://www.numberanalytics.com/blog/exposure-at-default-basics-guide](https://www.numberanalytics.com/blog/exposure-at-default-basics-guide)  
79. Changes in Credit Limit and Balance as Borrowers Approach Default \- ResearchGate, acessado em julho 15, 2025, [https://www.researchgate.net/figure/Changes-in-Credit-Limit-and-Balance-as-Borrowers-Approach-Default\_tbl3\_228423877](https://www.researchgate.net/figure/Changes-in-Credit-Limit-and-Balance-as-Borrowers-Approach-Default_tbl3_228423877)  
80. WO2007064617A2 \- Method and system for income estimation \- Google Patents, acessado em julho 15, 2025, [https://patents.google.com/patent/WO2007064617A2/en](https://patents.google.com/patent/WO2007064617A2/en)  
81. Income Estimation Models and A Dream \- Finahukuk, acessado em julho 15, 2025, [https://www.finahukuk.com/income-estimation-models-and-a-dream/](https://www.finahukuk.com/income-estimation-models-and-a-dream/)  
82. Evaluating forecast accuracy (MAE, RMSE, MAPE) | Intro to Time Series Class Notes, acessado em julho 15, 2025, [https://library.fiveable.me/intro-time-series/unit-8/evaluating-forecast-accuracy-mae-rmse-mape/study-guide/ijqkb0CAqRaHLBFi](https://library.fiveable.me/intro-time-series/unit-8/evaluating-forecast-accuracy-mae-rmse-mape/study-guide/ijqkb0CAqRaHLBFi)  
83. How to Assess the Effectiveness of Credit Scoring Models \- RiskSeal, acessado em julho 15, 2025, [https://riskseal.io/blog/how-to-assess-the-effectiveness-of-credit-scoring-models](https://riskseal.io/blog/how-to-assess-the-effectiveness-of-credit-scoring-models)  
84. Credit Score: A Comparison of Gradient Boosting with ... \- SAS Support, acessado em julho 15, 2025, [https://support.sas.com/resources/papers/proceedings18/1857-2018.pdf](https://support.sas.com/resources/papers/proceedings18/1857-2018.pdf)  
85. modelCalibration \- Compute R-square, RMSE, correlation, and sample mean error of predicted and observed EADs \- MATLAB \- MathWorks, acessado em julho 15, 2025, [https://www.mathworks.com/help/risk/tobit.modelcalibration.html](https://www.mathworks.com/help/risk/tobit.modelcalibration.html)  
86. Estimating Loss Given Default Based on Beta Regression \- ResearchGate, acessado em julho 15, 2025, [https://www.researchgate.net/publication/348049058\_Estimating\_Loss\_Given\_Default\_Based\_on\_Beta\_Regression](https://www.researchgate.net/publication/348049058_Estimating_Loss_Given_Default_Based_on_Beta_Regression)  
87. Model Loss Given Default \- MATLAB & Simulink \- MathWorks América Latina, acessado em julho 15, 2025, [https://la.mathworks.com/help/risk/comparing-lgd-models.html](https://la.mathworks.com/help/risk/comparing-lgd-models.html)  
88. Validation techniques and performance metrics for loss given default models | Request PDF, acessado em julho 15, 2025, [https://www.researchgate.net/publication/265268504\_Validation\_techniques\_and\_performance\_metrics\_for\_loss\_given\_default\_models](https://www.researchgate.net/publication/265268504_Validation_techniques_and_performance_metrics_for_loss_given_default_models)  
89. 0 Modeling Loss Given Default Regressions Xinlei Zhao First version \- OCC.gov, acessado em julho 15, 2025, [https://www.occ.gov/publications-and-resources/publications/economics/working-papers-new-frontiers-bank-risk-mgmt/pub-econ-working-paper-modeling-loss-given-default-reg.pdf](https://www.occ.gov/publications-and-resources/publications/economics/working-papers-new-frontiers-bank-risk-mgmt/pub-econ-working-paper-modeling-loss-given-default-reg.pdf)  
90. Machine learning prediction of loss given default in government-sponsored enterprise residential mortgages \- Journal of Risk Model Validation, acessado em julho 15, 2025, [https://www.risk.net/journal-of-risk-model-validation/7959987/machine-learning-prediction-of-loss-given-default-in-government-sponsored-enterprise-residential-mortgages](https://www.risk.net/journal-of-risk-model-validation/7959987/machine-learning-prediction-of-loss-given-default-in-government-sponsored-enterprise-residential-mortgages)  
91. Machine Learning based LGD Benchmark Model, acessado em julho 15, 2025, [https://firm.fm/wp-content/uploads/2024/03/20240229-AI-based-LGD-Benchmark-Model-by-Advisense.pdf](https://firm.fm/wp-content/uploads/2024/03/20240229-AI-based-LGD-Benchmark-Model-by-Advisense.pdf)  
92. Gradient Boosting Algorithm \- Complete Guide \- Corporate Finance Institute, acessado em julho 15, 2025, [https://corporatefinanceinstitute.com/resources/data-science/gradient-boosting/](https://corporatefinanceinstitute.com/resources/data-science/gradient-boosting/)  
93. Everything You Need to Know When Assessing Gradient Boosting Skills \- Alooba, acessado em julho 15, 2025, [https://www.alooba.com/skills/concepts/machine-learning/gradient-boosting/](https://www.alooba.com/skills/concepts/machine-learning/gradient-boosting/)  
94. A Novel Dynamic Ensemble Learning (DEL) Framework to Combat The Dataset Shift: The Case of Loss Given Default, acessado em julho 15, 2025, [https://www.crc.business-school.ed.ac.uk/sites/crc/files/2025-03/Novel-Dynamic-Ensemble-Learning-Framework-Combat-Dataset-Shift-Case-Loss-Given-Default.pdf](https://www.crc.business-school.ed.ac.uk/sites/crc/files/2025-03/Novel-Dynamic-Ensemble-Learning-Framework-Combat-Dataset-Shift-Case-Loss-Given-Default.pdf)  
95. Enhancing Credit Risk Prediction through an Ensemble of Explainable Model, acessado em julho 15, 2025, [https://www.researchgate.net/publication/391524362\_Enhancing\_Credit\_Risk\_Prediction\_through\_an\_Ensemble\_of\_Explainable\_Model](https://www.researchgate.net/publication/391524362_Enhancing_Credit_Risk_Prediction_through_an_Ensemble_of_Explainable_Model)  
96. Cracking the Code of LGD: A Masterclass in Advanced Loss Given Default Modeling, acessado em julho 15, 2025, [https://medium.com/@candemir13/cracking-the-code-of-lgd-a-masterclass-in-advanced-loss-given-default-modeling-2eed7b2c0be5](https://medium.com/@candemir13/cracking-the-code-of-lgd-a-masterclass-in-advanced-loss-given-default-modeling-2eed7b2c0be5)  
97. Credit risk modeling gradient boosting: How to Use Gradient Boosting for Credit Risk Analysis \- FasterCapital, acessado em julho 15, 2025, [https://fastercapital.com/content/Credit-risk-modeling-gradient-boosting--How-to-Use-Gradient-Boosting-for-Credit-Risk-Analysis.html](https://fastercapital.com/content/Credit-risk-modeling-gradient-boosting--How-to-Use-Gradient-Boosting-for-Credit-Risk-Analysis.html)  
98. 6 Common CECL backtesting mistakes & how to avoid them \- Abrigo, acessado em julho 15, 2025, [https://www.abrigo.com/blog/6-common-cecl-backtesting-mistakes-how-to-avoid-them/](https://www.abrigo.com/blog/6-common-cecl-backtesting-mistakes-how-to-avoid-them/)  
99. (PDF) AI Enhanced Revenue Modeling and Financial Foresight for Risk- Responsive Growth in Minority-Led Enterprises \- ResearchGate, acessado em julho 15, 2025, [https://www.researchgate.net/publication/390564309\_AI\_Enhanced\_Revenue\_Modeling\_and\_Financial\_Foresight\_for\_Risk-\_Responsive\_Growth\_in\_Minority-Led\_Enterprises](https://www.researchgate.net/publication/390564309_AI_Enhanced_Revenue_Modeling_and_Financial_Foresight_for_Risk-_Responsive_Growth_in_Minority-Led_Enterprises)  
100. AI Enhanced Revenue Modeling and Financial Foresight for Risk-Responsive Growth in Minority-Led Enterprises \- ijrpr, acessado em julho 15, 2025, [https://ijrpr.com/uploads/V6ISSUE3/IJRPR41090.pdf](https://ijrpr.com/uploads/V6ISSUE3/IJRPR41090.pdf)  
101. Make Risk Management Compliant, Robust, and Fail-Proof \- Evalueserve, acessado em julho 15, 2025, [https://www.evalueserve.com/case-study/make-risk-management-compliant-robust-fail-proof/](https://www.evalueserve.com/case-study/make-risk-management-compliant-robust-fail-proof/)  
102. Macro-economic model selection for Point-in-Time forecasting under IFRS-9 \- Amsshare, acessado em julho 15, 2025, [https://amsshare.com/macro-economic-model-selection-for-point-in-time-forecasting-under-ifrs-9/](https://amsshare.com/macro-economic-model-selection-for-point-in-time-forecasting-under-ifrs-9/)  
103. Role of Canary Testing and Champion/Challenger Modules in Credit Decision-Making, acessado em julho 15, 2025, [https://cloudbankin.com/loan-origination/enhancing-credit-decision-making-with-canary-deployments-and-champion-challenger-modules-an-ultimate-guide/](https://cloudbankin.com/loan-origination/enhancing-credit-decision-making-with-canary-deployments-and-champion-challenger-modules-an-ultimate-guide/)  
104. What is Champion/Challenger Test? \- Clay, acessado em julho 15, 2025, [https://www.clay.com/glossary/champion-challenger-test](https://www.clay.com/glossary/champion-challenger-test)  
105. Statistical Significance: Statistical Significance: Validating Results in the Champion Challenger Model \- FasterCapital, acessado em julho 15, 2025, [https://fastercapital.com/content/Statistical-Significance--Statistical-Significance--Validating-Results-in-the-Champion-Challenger-Model.html](https://fastercapital.com/content/Statistical-Significance--Statistical-Significance--Validating-Results-in-the-Champion-Challenger-Model.html)  
106. Champion-Challenger Model \- What Is It, Examples, Importance \- WallStreetMojo, acessado em julho 15, 2025, [https://www.wallstreetmojo.com/champion-challenger-model/](https://www.wallstreetmojo.com/champion-challenger-model/)  
107. Credit Risk Measurement: Alternatives for PD-LGD-EAD on the Horizon? \- GARP, acessado em julho 15, 2025, [https://www.garp.org/risk-intelligence/credit/credit-risk-measurement-alternatives-250207](https://www.garp.org/risk-intelligence/credit/credit-risk-measurement-alternatives-250207)  
108. PD – LGD Correlation Study, acessado em julho 15, 2025, [https://economics.hse.ru/data/2015/06/16/1084141036/2015%2006%2013%20Ermolova%20Penikas%20FEBS%202015.pdf](https://economics.hse.ru/data/2015/06/16/1084141036/2015%2006%2013%20Ermolova%20Penikas%20FEBS%202015.pdf)  
109. Modeling stressed LGDs for macroeconomic scenarios \- Moody's, acessado em julho 15, 2025, [https://www.moodys.com/web/en/us/insights/banking/modeling-stressed-lgds-for-macroeconomic-scenarios.html](https://www.moodys.com/web/en/us/insights/banking/modeling-stressed-lgds-for-macroeconomic-scenarios.html)  
110. Validation and Stress Testing of Credit Risk Models \- Cambridge Core \- Journals & Books Online, acessado em julho 15, 2025, [https://resolve.cambridge.org/core/services/aop-cambridge-core/content/view/CA0575259956441BE86BB656FAB17B96/9781316550915c5\_p186-234\_CBO.pdf/validation\_and\_stress\_testing\_of\_credit\_risk\_models.pdf](https://resolve.cambridge.org/core/services/aop-cambridge-core/content/view/CA0575259956441BE86BB656FAB17B96/9781316550915c5_p186-234_CBO.pdf/validation_and_stress_testing_of_credit_risk_models.pdf)  
111. Model Risk for Acceptable, but Imperfect, Discrimination and Calibration in Basel PD and LGD Models, acessado em julho 15, 2025, [https://www.cbr.ru/statichtml/file/135028/wp\_92.pdf](https://www.cbr.ru/statichtml/file/135028/wp_92.pdf)